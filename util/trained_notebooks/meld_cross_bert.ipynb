{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert --upgrade\n",
        "!pip install utils --upgrade\n",
        "!pip install urllib3 --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4G-wc9m5-va",
        "outputId": "a4f47a0c-289c-4129-b5e7-b26728f50ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_pretrained_bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.12.1+cu113)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.24.92-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.28.0,>=1.27.92\n",
            "  Downloading botocore-1.27.92-py3-none-any.whl (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 66.8 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 70.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.92->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.92->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 45.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.24.92 botocore-1.27.92 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.25.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (1.25.11)\n",
            "Collecting urllib3\n",
            "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.25.11\n",
            "    Uninstalling urllib3-1.25.11:\n",
            "      Successfully uninstalled urllib3-1.25.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.26.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTi67_d047LF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b08c7c4-6024-45e4-8d36-bbc0e2f21561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import cv2\n",
        "\n",
        "\n",
        "ltoi = {}\n",
        "emo_num = 0\n",
        "\n",
        "class MeldVideoDataset(Dataset):\n",
        "    def __init__(self, annotations_file):\n",
        "        self.data = []\n",
        "\n",
        "        data = pd.read_pickle(annotations_file)\n",
        "        max_audio_length = 0\n",
        "\n",
        "        global ltoi\n",
        "        global emo_num\n",
        "\n",
        "        for item in data:\n",
        "            video_features = item[0]\n",
        "            video_features = [cv2.resize(img, dsize=(64, 64)) for img in video_features if img != []]\n",
        "            audio_features = item[1]\n",
        "            text_features = item[2]\n",
        "            emotion = item[3]\n",
        "            if emotion not in ltoi:\n",
        "                ltoi[emotion] = emo_num\n",
        "                emo_num += 1\n",
        "\n",
        "            emotion = ltoi[emotion]\n",
        "\n",
        "            self.data.append((text_features, audio_features, video_features, emotion))\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        elem = self.data[idx]\n",
        "        #      text,    audio,   video,    emotion\n",
        "        return elem[0], elem[1], elem[2], elem[3]\n",
        "\n",
        "\n",
        "train_dataset = MeldVideoDataset('/content/drive/MyDrive/ИТМО/НИР3/notebooks/meld_train.pkl')\n",
        "test_dataset = MeldVideoDataset('/content/drive/MyDrive/ИТМО/НИР3/notebooks/meld_test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ltoi"
      ],
      "metadata": {
        "id": "jZHukF0IZQdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e5c342-2a1c-42d7-89a6-17a21df174c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neutral': 0,\n",
              " 'fear': 1,\n",
              " 'surprise': 2,\n",
              " 'joy': 3,\n",
              " 'disgust': 4,\n",
              " 'sadness': 5,\n",
              " 'anger': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[1]"
      ],
      "metadata": {
        "id": "6bwBGZ77_JfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjDQb1hx5DrJ",
        "outputId": "c3cbb4b6-d4ba-4d28-bac3-72ba8a823dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11911"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
      ],
      "metadata": {
        "id": "xPtZDqua5t6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "7Cqosam35uh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def multi_metrics(preds, y):\n",
        "    _, y_pred_tags = torch.max(preds, dim = 1)\n",
        "    _, y_tags = torch.max(y, dim = 1)\n",
        "    \n",
        "    y_pred_tags = y_pred_tags.cpu().data\n",
        "    y_tags = y_tags.cpu().data\n",
        "\n",
        "    acc = accuracy_score(y_tags, y_pred_tags, normalize=True)\n",
        "    prec = precision_score(y_tags, y_pred_tags, average='weighted')\n",
        "    f1 = f1_score(y_tags, y_pred_tags, average='weighted')\n",
        "    rec = recall_score(y_tags, y_pred_tags, average='weighted')\n",
        "    report = classification_report(y_tags, y_pred_tags, output_dict=True)\n",
        "    \n",
        "    return acc, prec, f1, rec, report\n",
        "\n",
        "\n",
        "def multi_metrics_for_valid(y_pred_tags, y_tags):\n",
        "    acc = accuracy_score(y_tags, y_pred_tags, normalize=True)\n",
        "    prec = precision_score(y_tags, y_pred_tags, average='weighted')\n",
        "    f1 = f1_score(y_tags, y_pred_tags, average='weighted')\n",
        "    rec = recall_score(y_tags, y_pred_tags, average='weighted')\n",
        "    report = classification_report(y_tags, y_pred_tags, output_dict=True)\n",
        "    \n",
        "    return acc, prec, f1, rec, report"
      ],
      "metadata": {
        "id": "SCALgZiJ5yk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    epoch_loss = 0.0\n",
        "    y_preds_tags_array = []\n",
        "    y_tags_array = []\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for idx, (video, audio, text, attr, labels) in enumerate(dataloader):\n",
        "            # features = features.unsqueeze(1)\n",
        "            \n",
        "            video = video.to(device)\n",
        "            text = text.to(device)\n",
        "            audio = audio.to(device)\n",
        "            attr = attr.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            predictions = model(text, audio, video, attention_mask=attr)[0]\n",
        "            \n",
        "            # loss = torch.nn.functional.cross_entropy(predictions, labels)\n",
        "\n",
        "            _, y_pred_tags = torch.max(predictions, dim = 1)\n",
        "            _, y_tags = torch.max(labels, dim = 1)\n",
        "            y_pred_tags = y_pred_tags.cpu().data\n",
        "            y_tags = y_tags.cpu().data\n",
        "            y_preds_tags_array.extend(predictions)\n",
        "            y_tags_array.extend(labels)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    acc, prec, f1, rec, report = multi_metrics_for_valid(y_preds_tags_array, y_tags_array)\n",
        "        \n",
        "    return epoch_loss / len(dataloader), acc, prec, f1, rec, report"
      ],
      "metadata": {
        "id": "UqdjO-Ke50dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = []\n",
        "    epoch_prec = []\n",
        "    epoch_f1 = []\n",
        "    epoch_rec = []\n",
        "    report = {}\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for idx, (video, audio, text, attr, labels) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        video = video.to(device)\n",
        "        text = text.to(device)\n",
        "        audio = audio.to(device)\n",
        "        attr = attr.to(device)\n",
        "        labels = labels.to(device) \n",
        "        \n",
        "        loss = model(text, audio, video, attention_mask=attr, labels=labels)\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "\n",
        "        # print(predictions, type(predictions))\n",
        "        # print(labels, type(labels))\n",
        "        # print(len(predictions), labels.shape)\n",
        "        \n",
        "        # print(predictions.shape, labels.shape)\n",
        "        # loss = torch.nn.functional.cross_entropy(predictions, labels)\n",
        "        # acc, prec, f1, rec, report = multi_metrics(predictions, labels)\n",
        "        # loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        # epoch_acc.append(acc)\n",
        "        # epoch_prec.append(prec)\n",
        "        # epoch_f1.append(f1)\n",
        "        # epoch_rec.append(rec)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_acc, epoch_prec, epoch_f1, epoch_rec, report"
      ],
      "metadata": {
        "id": "VXmafz9f52Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "BcDku9dm54mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "from string import punctuation \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "punctuations = list(punctuation)\n",
        "punkt = ['``','...',\"''\",'«','»','…','”','”','“','-','–','..']\n",
        "punctuations.extend(punkt)\n",
        "\n",
        "\n",
        "max_l = 25\n",
        "video_lengths = []\n",
        "group_size = 10\n",
        "overlap = 5\n",
        "\n",
        "BATCH_SIZE = 24\n",
        "TEXT_MAX_LENGTH = 50\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, video_list = [], []\n",
        "    text_list, att_masks = [], []\n",
        "    audio_list = []\n",
        "\n",
        "    for (_text_features, _audio_features, _video_features, _label) in batch:\n",
        "        global max_l\n",
        "        global video_lengths\n",
        "\n",
        "        # label_map = [0.0] * 7\n",
        "        # label_map[_label] = 1.0\n",
        "        # label_list.append(label_map)\n",
        "\n",
        "        label_list.append(_label)\n",
        "\n",
        "        float_f = []\n",
        "\n",
        "        video_lengths.append(len(_video_features))\n",
        "\n",
        "        ind = 0\n",
        "        while ind < max_l:\n",
        "            group = []\n",
        "            end_pos = ind + overlap\n",
        "\n",
        "            for i in range(ind, end_pos):\n",
        "                if i >= len(_video_features):\n",
        "                    break\n",
        "                f = _video_features[i]\n",
        "                if f != []:\n",
        "                    f = rgb2gray(f)\n",
        "                else:\n",
        "                    f = [[0 for col in range(64)] for row in range(64)]\n",
        "                f = torch.FloatTensor(f)\n",
        "\n",
        "                group.append(f)\n",
        "            \n",
        "            for i in range(len(group), group_size):\n",
        "                group.append(torch.zeros(64, 64))\n",
        "\n",
        "            group = torch.transpose(pad_sequence(group), 0, 1)\n",
        "            float_f.append(group)\n",
        "            ind += overlap\n",
        "            \n",
        "        try:\n",
        "            X = torch.transpose(pad_sequence(float_f), 0, 1)\n",
        "        except Exception:\n",
        "            print(len(float_f), float_f[0].shape, float_f[1].shape)\n",
        "            raise Exception\n",
        "\n",
        "        # text = \" \".join([word for word in tokenizer.tokenize(_text_features) if word not in stops and word.isalpha and word not in punctuations])\n",
        "        pt = tokenizer(_text_features, padding=\"max_length\", add_special_tokens=True, max_length=TEXT_MAX_LENGTH, return_tensors=\"pt\")\n",
        "\n",
        "        text_list.append(pt[\"input_ids\"][0][:TEXT_MAX_LENGTH])\n",
        "        att_masks.append(pt[\"attention_mask\"][0][:TEXT_MAX_LENGTH])\n",
        "        audio_list.append(_audio_features)\n",
        "        video_list.append(X)\n",
        "\n",
        "    # 3d\n",
        "    video_features_tensor = torch.transpose(pad_sequence(video_list), 0, 1)\n",
        "    \n",
        "    audio_tensor = torch.FloatTensor(audio_list)\n",
        "    audio_tensor = torch.unsqueeze(audio_tensor, 1)\n",
        "\n",
        "    # print([t.shape for t in text_list])\n",
        "\n",
        "    text_tensor = torch.stack(text_list)\n",
        "    att_tensor = torch.stack(att_masks)\n",
        "\n",
        "    label_tensor = torch.FloatTensor(label_list)\n",
        "\n",
        "    # print(video_features_tensor.shape, audio_tensor.shape, text_tensor.shape)\n",
        "\n",
        "    return video_features_tensor, audio_tensor, text_tensor, att_tensor, label_tensor\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "Zp2dS5QQ56IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from pytorch_pretrained_bert.file_utils import cached_path\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import shutil\n",
        "import torch.nn.functional as F\n",
        "import tarfile\n",
        "import tempfile\n",
        "import sys\n",
        "from io import open\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "from utils import *\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "PRETRAINED_MODEL_ARCHIVE_MAP = {\n",
        "    'bert-base-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz\",\n",
        "    'bert-large-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz\",\n",
        "    'bert-base-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz\",\n",
        "    'bert-large-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz\",\n",
        "    'bert-base-multilingual-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased.tar.gz\",\n",
        "    'bert-base-multilingual-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz\",\n",
        "    'bert-base-chinese': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz\",\n",
        "}\n",
        "\n",
        "def bi_modal_attention(x, y):\n",
        "    m1 = torch.matmul(x,y.transpose(-1, -2))\n",
        "    n1 = nn.Softmax(dim=-1)(m1)\n",
        "    o1 = torch.matmul(n1,y)\n",
        "    a1 = torch.mul(o1, x)\n",
        "\n",
        "    m2 = torch.matmul(y,x.transpose(-1, -2))\n",
        "    n2 = nn.Softmax(dim=-1)(m2)\n",
        "    o2 = torch.matmul(n2,x)\n",
        "    a2 = torch.mul(o2, y)\n",
        "    return a1,a2\n",
        "\n",
        "def gelu(x):\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n",
        "\n",
        "\n",
        "class BertConfig(object):\n",
        "    def __init__(self,\n",
        "                 vocab_size_or_config_json_file,\n",
        "                 hidden_size=768,\n",
        "                 num_hidden_layers=12,\n",
        "                 num_attention_heads=12,\n",
        "                 intermediate_size=3072,\n",
        "                 hidden_act=\"gelu\",\n",
        "                 hidden_dropout_prob=0.1,\n",
        "                 attention_probs_dropout_prob=0.1,\n",
        "                 max_position_embeddings=512,\n",
        "                 type_vocab_size=2,\n",
        "                 initializer_range=0.02):\n",
        "        if isinstance(vocab_size_or_config_json_file, str) or (sys.version_info[0] == 2\n",
        "                        and isinstance(vocab_size_or_config_json_file, unicode)):\n",
        "            with open(vocab_size_or_config_json_file, \"r\", encoding='utf-8') as reader:\n",
        "                json_config = json.loads(reader.read())\n",
        "            for key, value in json_config.items():\n",
        "                self.__dict__[key] = value\n",
        "        elif isinstance(vocab_size_or_config_json_file, int):\n",
        "            self.vocab_size = vocab_size_or_config_json_file\n",
        "            self.hidden_size = hidden_size\n",
        "            self.num_hidden_layers = num_hidden_layers\n",
        "            self.num_attention_heads = num_attention_heads\n",
        "            self.hidden_act = hidden_act\n",
        "            self.intermediate_size = intermediate_size\n",
        "            self.hidden_dropout_prob = hidden_dropout_prob\n",
        "            self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
        "            self.max_position_embeddings = max_position_embeddings\n",
        "            self.type_vocab_size = type_vocab_size\n",
        "            self.initializer_range = initializer_range\n",
        "        else:\n",
        "            raise ValueError(\"First argument must be either a vocabulary size (int)\"\n",
        "                             \"or the path to a pretrained model config file (str)\")\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, json_object):\n",
        "        \"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"\n",
        "        config = BertConfig(vocab_size_or_config_json_file=-1)\n",
        "        for key, value in json_object.items():\n",
        "            config.__dict__[key] = value\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_json_file(cls, json_file):\n",
        "        \"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"\n",
        "        with open(json_file, \"r\", encoding='utf-8') as reader:\n",
        "            text = reader.read()\n",
        "        return cls.from_dict(json.loads(text))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "try:\n",
        "    from apex.normalization.fused_layer_norm import FusedLayerNorm as BertLayerNorm\n",
        "except ImportError:\n",
        "    print(\"Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\")\n",
        "    class BertLayerNorm(nn.Module):\n",
        "        def __init__(self, hidden_size, eps=1e-12):\n",
        "            \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "            \"\"\"\n",
        "            super(BertLayerNorm, self).__init__()\n",
        "            self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "            self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "            self.variance_epsilon = eps\n",
        "\n",
        "        def forward(self, x):\n",
        "            u = x.mean(-1, keepdim=True)\n",
        "            s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "            x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "            return self.weight * x + self.bias\n",
        "\n",
        "class BertEmbeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(BertEmbeddings, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
        "        # any TensorFlow checkpoint file\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids,token_type_ids=None):\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
        "        #在第一维增加一维，`input_ids`: a torch.LongTensor of shape [batch_size, sequence_length] with the word token indices in the vocabulary\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "        #对应paper中segment embeddings \n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "        words_embeddings = self.word_embeddings(input_ids)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "        \n",
        "        embeddings = words_embeddings + position_embeddings + token_type_embeddings \n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "        \n",
        "class BertSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfAttention, self).__init__()\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                \"The hidden size (%d) is not a multiple of the number of attention \"\n",
        "                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads))\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "    def transpose_for_scores(self, x):\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
        "        x = x.view(*new_x_shape)\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, hidden_states,audio_data, attention_mask):\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
        "        attention_scores = attention_scores + attention_mask\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)\n",
        "        return context_layer\n",
        "\n",
        "\n",
        "class BertSelfOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states,input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "\n",
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertAttention, self).__init__()\n",
        "        self.self = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor,audio_data,attention_mask):\n",
        "        self_output = self.self(input_tensor,audio_data,attention_mask)\n",
        "        attention_output = self.output(self_output, input_tensor)\n",
        "        return attention_output\n",
        "\n",
        "\n",
        "class BertIntermediate(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertIntermediate, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "        if isinstance(config.hidden_act, str) or (sys.version_info[0] == 2 and isinstance(config.hidden_act, unicode)):\n",
        "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
        "        else:\n",
        "            self.intermediate_act_fn = config.hidden_act\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertOutput(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        \n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BertLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertLayer, self).__init__()\n",
        "        self.attention = BertAttention(config)#过一层Multi-Head Attention 然后与input加和过一层Norm层\n",
        "        self.intermediate = BertIntermediate(config)#过一层Linear然后过gelu激活函数\n",
        "        self.output = BertOutput(config)#过一层Linear然后过dropout然后与input加和过norm\n",
        "\n",
        "    def forward(self, hidden_states,all_audio_data,attention_mask):\n",
        "        attention_output = self.attention(hidden_states,all_audio_data,attention_mask)\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        return layer_output\n",
        "\n",
        "        \n",
        "class BertFinetun(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertFinetun, self).__init__()\n",
        "        self.proj_t = nn.Conv1d(768,30, kernel_size=1, padding=0, bias=False)\n",
        "        self.proj_a = nn.Conv1d(5,30, kernel_size=1, padding=0, bias=False)\n",
        "\n",
        "        ch1, ch2 = 32, 48\n",
        "        k1, k2 = (5, 5, 5), (2, 3, 3)  # 3d kernel size\n",
        "        s1, s2 = (2, 2, 2), (2, 2, 2)  # 3d strides\n",
        "        pd1, pd2 = (1, 1, 1), (1, 1, 1)  # 3d padding\n",
        "        self.proj_v_1 = nn.Conv3d(in_channels=5, out_channels=ch1, \n",
        "                                kernel_size=k1, stride=s1,\n",
        "                                padding=pd1, bias=False)\n",
        "        self.proj_v_2 = nn.Conv3d(in_channels=ch1, out_channels=ch2, \n",
        "                                  kernel_size=k2, stride=s2,\n",
        "                                  padding=pd2, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(ch1)\n",
        "        self.bn2 = nn.BatchNorm3d(ch2)\n",
        "        self.drop_video = nn.Dropout3d(0.1)\n",
        "\n",
        "        self.fc1 = nn.Linear(36864, 4608)\n",
        "        self.fc2 = nn.Linear(4608, 2500)\n",
        "\n",
        "        # self.fc1 = nn.Linear(36864, 2304)\n",
        "        # self.fc2 = nn.Linear(2304, 256)\n",
        "        # self.fc3 = nn.Linear(256, 50)\n",
        "        \n",
        "        # self.fc = nn.Linear(36864, 50)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "        self.audio_weight_1 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "        self.text_weight_1 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "        self.video_weight_1 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "        self.bias = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "        self.audio_weight_1.data.fill_(1)\n",
        "        self.text_weight_1.data.fill_(1)\n",
        "        self.video_weight_1.data.fill_(1)\n",
        "        self.bias.data.fill_(0)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dense = nn.Linear(768, 768)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.LayerNorm1 = BertLayerNorm(768)\n",
        "        \n",
        "        \n",
        "    def forward(self, hidden_states,pooled_output,audio_data,video_data,attention_mask):\n",
        "        attention_mask = attention_mask.squeeze(1)\n",
        "        attention_mask_ = attention_mask.permute(0, 2, 1)\n",
        "        text_data = hidden_states\n",
        "        text_data = text_data.transpose(1, 2)\n",
        "        text_data = self.proj_t(text_data)\n",
        "        text_data = text_data.transpose(1, 2)\n",
        "        text_data_1 = text_data.reshape(-1).cpu().detach().numpy()\n",
        "        weights = np.sqrt(np.linalg.norm(text_data_1,ord=2))\n",
        "        text_data = text_data/weights\n",
        "\n",
        "        audio_data = audio_data.transpose(1, 2)\n",
        "        audio_data = self.proj_a(audio_data)\n",
        "        audio_data = audio_data.transpose(1, 2)\n",
        "\n",
        "        video_data = self.proj_v_1(video_data)\n",
        "        video_data = self.bn1(video_data)\n",
        "        video_data = self.relu(video_data)\n",
        "        video_data = self.drop_video(video_data)\n",
        "\n",
        "        video_data = self.proj_v_2(video_data)\n",
        "        video_data = self.bn2(video_data)\n",
        "        video_data = self.relu(video_data)\n",
        "        video_data = self.drop_video(video_data)\n",
        "\n",
        "        video_data = video_data.view(video_data.size(0), -1)\n",
        "        video_data = F.relu(self.fc1(video_data))\n",
        "        video_data = F.relu(self.fc2(video_data))\n",
        "\n",
        "        # video_data = F.relu(self.fc1(video_data))\n",
        "        # video_data = F.relu(self.fc2(video_data))\n",
        "        # video_data = F.relu(self.fc3(video_data))\n",
        "\n",
        "        # video_data = self.fc1(video_data)\n",
        "        # video_data = self.fc2(video_data)\n",
        "\n",
        "        # video_data = self.fc(video_data)\n",
        "        # print(video_data.shape, text_data.shape, audio_data.shape)\n",
        "\n",
        "        # video_data = video_data.reshape((video_data.shape[0], video_data.shape[1] // 30, 30))\n",
        "        \n",
        "        # print(video_data.shape, text_data.shape, audio_data.shape)\n",
        "\n",
        "        # video_data = video_data.unsqueeze(1)\n",
        "\n",
        "        video_data = video_data.reshape((video_data.shape[0], 50, 50))\n",
        "        video_att = video_data\n",
        "        video_att = self.activation(video_att)\n",
        "        \n",
        "        # video_att = torch.matmul(video_data,video_data.transpose(-1, -2))\n",
        "        # video_att = self.activation(video_att)\n",
        "\n",
        "        text_att = torch.matmul(text_data,text_data.transpose(-1, -2))\n",
        "        text_att1 = self.activation(text_att)\n",
        "\n",
        "        audio_att = torch.matmul(audio_data,audio_data.transpose(-1, -2))\n",
        "        audio_att = self.activation(audio_att)\n",
        "\n",
        "        # print(video_att.shape, text_att.shape, audio_att.shape)\n",
        "\n",
        "        audio_weight_1 = self.audio_weight_1\n",
        "        text_weight_1 = self.text_weight_1\n",
        "        video_weight_1 = self.video_weight_1\n",
        "        bias = self.bias\n",
        "        \n",
        "        fusion_att = text_weight_1 * text_att1 + audio_weight_1 * audio_att\n",
        "        # print(fusion_att.shape, video_weight_1.shape, video_att.shape)\n",
        "\n",
        "        fusion_att = fusion_att + video_weight_1 * video_att + bias \n",
        "\n",
        "        fusion_att1 = self.activation(fusion_att)\n",
        "        fusion_att = fusion_att+ attention_mask+ attention_mask_\n",
        "        fusion_att = nn.Softmax(dim=-1)(fusion_att)\n",
        "        fusion_att = self.dropout1(fusion_att)\n",
        "        \n",
        "        fusion_data = torch.matmul(fusion_att,hidden_states)\n",
        "        fusion_data = fusion_data+hidden_states\n",
        "\n",
        "        hidden_states_new = self.dense(fusion_data)\n",
        "        hidden_states_new = self.dropout(hidden_states_new)\n",
        "        hidden_states_new = self.LayerNorm1(hidden_states_new)\n",
        "        hidden_states_new = hidden_states_new[:,0]\n",
        "        return hidden_states_new,text_att1,fusion_att1\n",
        "\n",
        "\n",
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertEncoder, self).__init__()\n",
        "        layer = BertLayer(config)#Transformer block\n",
        "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_attention_heads)])\n",
        "\n",
        "    def forward(self, hidden_states,all_audio_data,attention_mask, output_all_encoded_layers=True):\n",
        "        all_encoder_layers = []\n",
        "        for layer_module in self.layer:\n",
        "            hidden_states = layer_module(hidden_states,all_audio_data, attention_mask)\n",
        "            if output_all_encoded_layers:\n",
        "                all_encoder_layers.append(hidden_states)\n",
        "        if not output_all_encoded_layers:\n",
        "            all_encoder_layers.append(hidden_states)\n",
        "        return all_encoder_layers\n",
        "\n",
        "\n",
        "class BertPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertPooler, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "\n",
        "class BertPreTrainedModel(nn.Module):\n",
        "    def __init__(self, config, *inputs, **kwargs):\n",
        "        super(BertPreTrainedModel, self).__init__()\n",
        "        if not isinstance(config, BertConfig):\n",
        "            raise ValueError(\n",
        "                \"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"\n",
        "                \"To create a model from a Google pretrained model use \"\n",
        "                \"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\".format(\n",
        "                    self.__class__.__name__, self.__class__.__name__\n",
        "                ))\n",
        "        self.config = config\n",
        "\n",
        "    def init_bert_weights(self, module):\n",
        "        \"\"\" Initialize the weights.\n",
        "        \"\"\"\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        elif isinstance(module, BertLayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, pretrained_model_name_or_path, state_dict=None, cache_dir=None,\n",
        "                        from_tf=False, *inputs, **kwargs):\n",
        "        if pretrained_model_name_or_path in PRETRAINED_MODEL_ARCHIVE_MAP:\n",
        "            archive_file = PRETRAINED_MODEL_ARCHIVE_MAP[pretrained_model_name_or_path]\n",
        "        else:\n",
        "            archive_file = pretrained_model_name_or_path\n",
        "        # redirect to the cache, if necessary\n",
        "        try:\n",
        "            resolved_archive_file = cached_path(archive_file, cache_dir=cache_dir)\n",
        "        except EnvironmentError:\n",
        "            logger.error(\n",
        "                \"Model name '{}' was not found in model name list ({}). \"\n",
        "                \"We assumed '{}' was a path or url but couldn't find any file \"\n",
        "                \"associated to this path or url.\".format(\n",
        "                    pretrained_model_name_or_path,\n",
        "                    ', '.join(PRETRAINED_MODEL_ARCHIVE_MAP.keys()),\n",
        "                    archive_file))\n",
        "            return None\n",
        "        if resolved_archive_file == archive_file:\n",
        "            logger.info(\"loading archive file {}\".format(archive_file))\n",
        "        else:\n",
        "            logger.info(\"loading archive file {} from cache at {}\".format(\n",
        "                archive_file, resolved_archive_file))\n",
        "        tempdir = None\n",
        "        if os.path.isdir(resolved_archive_file) or from_tf:\n",
        "            serialization_dir = resolved_archive_file\n",
        "        else:\n",
        "            # Extract archive to temp dir\n",
        "            tempdir = tempfile.mkdtemp()\n",
        "            logger.info(\"extracting archive file {} to temp dir {}\".format(\n",
        "                resolved_archive_file, tempdir))\n",
        "            with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
        "                archive.extractall(tempdir)\n",
        "            serialization_dir = tempdir\n",
        "        # Load config\n",
        "        config_file = os.path.join(serialization_dir, CONFIG_NAME)\n",
        "        config = BertConfig.from_json_file(config_file)\n",
        "        logger.info(\"Model config {}\".format(config))\n",
        "        # Instantiate model.\n",
        "        model = cls(config, *inputs, **kwargs)\n",
        "        if state_dict is None and not from_tf:\n",
        "            weights_path = os.path.join(serialization_dir, WEIGHTS_NAME)\n",
        "            state_dict = torch.load(weights_path, map_location=device)\n",
        "        if tempdir:\n",
        "            # Clean up temp dir\n",
        "            shutil.rmtree(tempdir)\n",
        "        # Load from a PyTorch state_dict\n",
        "        old_keys = []\n",
        "        new_keys = []\n",
        "        for key in state_dict.keys():\n",
        "            new_key = None\n",
        "            if 'gamma' in key:\n",
        "                new_key = key.replace('gamma', 'weight')\n",
        "            if 'beta' in key:\n",
        "                new_key = key.replace('beta', 'bias')\n",
        "            if new_key:\n",
        "                old_keys.append(key)\n",
        "                new_keys.append(new_key)\n",
        "        for old_key, new_key in zip(old_keys, new_keys):\n",
        "            state_dict[new_key] = state_dict.pop(old_key)\n",
        "\n",
        "        missing_keys = []\n",
        "        unexpected_keys = []\n",
        "        error_msgs = []\n",
        "        # copy state_dict so _load_from_state_dict can modify it\n",
        "        metadata = getattr(state_dict, '_metadata', None)\n",
        "        state_dict = state_dict.copy()\n",
        "        if metadata is not None:\n",
        "            state_dict._metadata = metadata\n",
        "\n",
        "        def load(module, prefix=''):\n",
        "            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
        "            module._load_from_state_dict(\n",
        "                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
        "            for name, child in module._modules.items():\n",
        "                if child is not None:\n",
        "                    load(child, prefix + name + '.')\n",
        "        start_prefix = ''\n",
        "        if not hasattr(model, 'bert') and any(s.startswith('bert.') for s in state_dict.keys()):\n",
        "            start_prefix = 'bert.'\n",
        "        load(model, prefix=start_prefix)\n",
        "        if len(missing_keys) > 0:\n",
        "            logger.info(\"Weights of {} not initialized from pretrained model: {}\".format(\n",
        "                model.__class__.__name__, missing_keys))\n",
        "        if len(unexpected_keys) > 0:\n",
        "            logger.info(\"Weights from pretrained model not used in {}: {}\".format(\n",
        "                model.__class__.__name__, unexpected_keys))\n",
        "        if len(error_msgs) > 0:\n",
        "            raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
        "                               model.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
        "        return model\n",
        "\n",
        "\n",
        "class BertModel(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super(BertModel, self).__init__(config)\n",
        "        self.embeddings = BertEmbeddings(config)\n",
        "        self.encoder = BertEncoder(config)\n",
        "        self.pooler = BertPooler(config)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids,all_audio_data,token_type_ids=None, attention_mask=None,output_all_encoded_layers=True):\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones_like(input_ids)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "        # We create a 3D attention mask from a 2D tensor mask.\n",
        "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
        "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
        "        # this attention mask is more simple than the triangular masking of causal attention\n",
        "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and -10000.0 for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "        embedding_output = self.embeddings(input_ids,token_type_ids)\n",
        "        encoded_layers = self.encoder(embedding_output,\n",
        "                                      all_audio_data,\n",
        "                                      extended_attention_mask,\n",
        "                                      output_all_encoded_layers=output_all_encoded_layers)\n",
        "        sequence_output = encoded_layers[-1]#选取最后一层Encoder的输出\n",
        "        pooled_output = self.pooler(sequence_output)\n",
        "        if not output_all_encoded_layers:\n",
        "            encoded_layers = encoded_layers[-1]\n",
        "        return sequence_output, pooled_output,extended_attention_mask\n",
        "\n",
        "\n",
        "class BertForSequenceClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super(BertForSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.BertFinetun = BertFinetun(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)#拿出来CLS的表示dimension = 768\n",
        "        self.classifier = nn.Linear(config.hidden_size, 1)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, all_audio_data,video_data,token_type_ids=None, attention_mask=None, labels=None):\n",
        "        encoder_lastoutput, pooled_output, extend_mask = self.bert(input_ids,all_audio_data,token_type_ids, attention_mask, output_all_encoded_layers=True)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        pooled_output,text_att,fusion_att = self.BertFinetun(encoder_lastoutput,pooled_output,all_audio_data,video_data,extend_mask)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        if labels is not None:\n",
        "            loss = 0.5 * (logits.view(-1) - labels) ** 2 \n",
        "            return loss\n",
        "        else:\n",
        "            return logits,text_att,fusion_att"
      ],
      "metadata": {
        "id": "rcuNwge058jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertFinetun(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertFinetun, self).__init__()\n",
        "        self.proj_t = nn.Conv1d(768,30, kernel_size=1, padding=0, bias=False)\n",
        "        self.proj_a = nn.Conv1d(128,30, kernel_size=1, padding=0, bias=False)\n",
        "\n",
        "        ch1 = 32\n",
        "        k1 = (4, 4, 4)  # 3d kernel size\n",
        "        s1 = (2, 2, 1)  # 3d strides\n",
        "        pd1 = (1, 1, 2)  # 3d padding\n",
        "        self.proj_v_1 = nn.Conv3d(in_channels=5, out_channels=ch1, \n",
        "                                kernel_size=k1, stride=s1,\n",
        "                                padding=pd1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(ch1)\n",
        "        self.drop_video = nn.Dropout3d(0.1)\n",
        "        self.lstm = nn.LSTM(input_size=6656, hidden_size=30, num_layers=2, batch_first=True)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "        self.audio_weight_1 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "        self.text_weight_1 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "        self.video_weight_1 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "        self.bias = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
        "        self.audio_weight_1.data.fill_(1)\n",
        "        self.text_weight_1.data.fill_(1)\n",
        "        self.video_weight_1.data.fill_(1)\n",
        "        self.bias.data.fill_(0)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dense = nn.Linear(768, 768)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.LayerNorm1 = BertLayerNorm(768)\n",
        "        \n",
        "        \n",
        "    def forward(self, hidden_states,pooled_output,audio_data,video_data,attention_mask):\n",
        "        attention_mask = attention_mask.squeeze(1)\n",
        "        attention_mask_ = attention_mask.permute(0, 2, 1)\n",
        "        text_data = hidden_states\n",
        "        text_data = text_data.transpose(1, 2)\n",
        "        text_data = self.proj_t(text_data)\n",
        "        text_data = text_data.transpose(1, 2)\n",
        "        text_data_1 = text_data.reshape(-1).cpu().detach().numpy()\n",
        "        weights = np.sqrt(np.linalg.norm(text_data_1,ord=2))\n",
        "        text_data = text_data/weights\n",
        "\n",
        "        audio_data = audio_data.transpose(1, 2)\n",
        "        audio_data = self.proj_a(audio_data)\n",
        "        audio_data = audio_data.transpose(1, 2)\n",
        "\n",
        "        video_data = self.proj_v_1(video_data)\n",
        "        video_data = self.bn1(video_data)\n",
        "\n",
        "        # print(video_data.shape)\n",
        "        video_data = video_data.reshape((video_data.shape[0], 50, 6656))\n",
        "        # video_data = video_data.view(video_data.size(0), -1)\n",
        "        # print(video_data.shape)\n",
        "\n",
        "        video_data, (_, _) = self.lstm(video_data)\n",
        "        # print(video_data.shape, text_data.shape, audio_data.shape)\n",
        "        \n",
        "        video_att = torch.matmul(video_data,video_data.transpose(-1, -2))\n",
        "        video_att = self.activation(video_att)\n",
        "\n",
        "        text_att = torch.matmul(text_data,text_data.transpose(-1, -2))\n",
        "        text_att1 = self.activation(text_att)\n",
        "\n",
        "        audio_att = torch.matmul(audio_data,audio_data.transpose(-1, -2))\n",
        "        audio_att = self.activation(audio_att)\n",
        "\n",
        "        # print(video_att.shape, text_att.shape, audio_att.shape)\n",
        "\n",
        "        audio_weight_1 = self.audio_weight_1\n",
        "        text_weight_1 = self.text_weight_1\n",
        "        video_weight_1 = self.video_weight_1\n",
        "        bias = self.bias\n",
        "        \n",
        "        fusion_att = text_weight_1 * text_att1 + audio_weight_1 * audio_att\n",
        "        # print(fusion_att.shape, video_weight_1.shape, video_att.shape)\n",
        "\n",
        "        fusion_att = fusion_att + video_weight_1 * video_att + bias \n",
        "\n",
        "        fusion_att1 = self.activation(fusion_att)\n",
        "        fusion_att = fusion_att+ attention_mask+ attention_mask_\n",
        "        fusion_att = nn.Softmax(dim=-1)(fusion_att)\n",
        "        fusion_att = self.dropout1(fusion_att)\n",
        "        \n",
        "        fusion_data = torch.matmul(fusion_att,hidden_states)\n",
        "        fusion_data = fusion_data+hidden_states\n",
        "\n",
        "        hidden_states_new = self.dense(fusion_data)\n",
        "        hidden_states_new = self.dropout(hidden_states_new)\n",
        "        hidden_states_new = self.LayerNorm1(hidden_states_new)\n",
        "        hidden_states_new = hidden_states_new[:,0]\n",
        "        return hidden_states_new,text_att1,fusion_att1"
      ],
      "metadata": {
        "id": "Go_g1yot8WOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ],
      "metadata": {
        "id": "vnAsd9C79JqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_NAME = '/content/uncased_L-12_H-768_A-12/bert_config.json'\n",
        "WEIGHTS_NAME = '/content/drive/MyDrive/ИТМО/НИР3/notebooks/pytorch_model.bin'"
      ],
      "metadata": {
        "id": "ImCCjds49HDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns    \n",
        "\n",
        "\n",
        "def accuracy_7(out, labels):\n",
        "    return np.sum(np.round(out) == np.round(labels)) / float(len(labels))\n",
        "\n",
        "\n",
        "def multi_metrics_for_valid_with_confusion(y_pred_tags, y_tags):\n",
        "    # print(y_pred_tags)\n",
        "    # print(y_tags)\n",
        "    y_pred_tags = np.round(y_pred_tags)\n",
        "    y_tags = np.round(y_tags)\n",
        "    acc = accuracy_score(y_tags, y_pred_tags, normalize=True)\n",
        "    prec = precision_score(y_tags, y_pred_tags, average='weighted')\n",
        "    f1 = f1_score(y_tags, y_pred_tags, average='weighted')\n",
        "    rec = recall_score(y_tags, y_pred_tags, average='weighted')\n",
        "    report = classification_report(y_tags, y_pred_tags, output_dict=True)\n",
        "    labels = ['neu', 'fear', 'surp', 'joy', 'disg', 'sad', 'ang']\n",
        "    matrix = confusion_matrix(y_tags, y_pred_tags)\n",
        "\n",
        "    acc7 = accuracy_7(y_pred_tags, y_tags)\n",
        "    \n",
        "    return acc, acc7, prec, f1, rec, report, matrix\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    epoch_loss = 0.0\n",
        "    y_preds_tags_array = []\n",
        "    y_tags_array = []\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for idx, (video, audio, text, attr, labels) in enumerate(dataloader):\n",
        "            # features = features.unsqueeze(1)\n",
        "            \n",
        "            video = video.to(device)\n",
        "            text = text.to(device)\n",
        "            audio = audio.to(device)\n",
        "            attr = attr.to(device)\n",
        "            labels = labels.to(device) \n",
        "            \n",
        "            predictions = model(text, audio, video, attention_mask=attr)[0]\n",
        "            \n",
        "            # loss = torch.nn.functional.cross_entropy(predictions, labels)\n",
        "\n",
        "            # _, y_pred_tags = torch.max(predictions, dim = 1)\n",
        "            # _, y_tags = torch.max(labels, dim = 1)\n",
        "            # y_pred_tags = y_pred_tags.cpu().data\n",
        "            # y_tags = y_tags.cpu().data\n",
        "            predictions = predictions.cpu().data\n",
        "            predictions = [predictions[i][0].item() for i in range(len(predictions))]\n",
        "            labels = labels.cpu().data\n",
        "            labels = [labels[i].item() for i in range(len(labels))]\n",
        "\n",
        "            y_preds_tags_array.extend(predictions)\n",
        "            y_tags_array.extend(labels)\n",
        "\n",
        "            # epoch_loss += loss.item()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    acc, acc_7, prec, f1, rec, report, matrix = multi_metrics_for_valid_with_confusion(y_preds_tags_array, y_tags_array)\n",
        "        \n",
        "    return epoch_loss / len(dataloader), acc, acc_7, prec, f1, rec, report, matrix"
      ],
      "metadata": {
        "id": "We0Eo_A46USC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", cache_dir=None, num_labels = 7)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ33o1XF6LA_",
        "outputId": "552b0be8-3d61-481c-fc9a-0428ed0ad6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:18<00:00, 22394174.47B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "N_EPOCHS = 50\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 2e-6, eps = 1e-8)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "best_valid_acc = 0.0\n",
        "best_valid_acc_7 = 0.0\n",
        "best_valid_prec = 0.0\n",
        "best_valid_f1 = 0.0\n",
        "best_valid_rec = 0.0\n",
        "result_report = {}\n",
        "result_matrix = {}\n",
        "\n",
        "for epoch in tqdm(range(N_EPOCHS)):\n",
        "    train_loss, train_acc, train_prec, train_f1, train_rec, _ = train(model, train_dataloader, optimizer, criterion)\n",
        "    valid_loss, valid_acc, valid_acc_7, valid_prec, valid_f1, valid_rec, report, matrix = evaluate(model, valid_dataloader, criterion)\n",
        "\n",
        "    if valid_acc >= best_valid_acc:\n",
        "        result_report = report\n",
        "        result_matrix = matrix\n",
        "    \n",
        "    best_valid_acc = max(best_valid_acc, valid_acc)\n",
        "    best_valid_acc_7 = max(best_valid_acc_7, valid_acc_7)\n",
        "    best_valid_prec = max(best_valid_prec, valid_prec)\n",
        "    best_valid_rec = max(best_valid_rec, valid_rec)\n",
        "    best_valid_f1 = max(best_valid_f1, valid_f1)\n",
        "\n",
        "\n",
        "print(f\"Best valid acc = {best_valid_acc}\")\n",
        "print(f\"Best valid acc 7 = {best_valid_acc_7}\")\n",
        "print(f\"Best valid prec = {best_valid_prec}\")\n",
        "print(f\"Best valid f1 = {best_valid_f1}\")\n",
        "print(f\"Best valid rec = {best_valid_rec}\")\n",
        "print(f'Classification report = \\n {json.dumps(result_report, sort_keys=True, indent=4)}')\n",
        "\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(result_matrix, annot=True, fmt='g', ax=ax);\n",
        "labels = ['neu', 'fear', 'surp', 'joy', 'disg', 'sad', 'ang']\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fh0ZyF_xBJ58",
        "outputId": "28f3ad40-74da-4e2e-d760-d7c891dc3691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [2:46:30<00:00, 199.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best valid acc = 0.41335740072202165\n",
            "Best valid acc 7 = 0.41335740072202165\n",
            "Best valid prec = 0.5326200070696823\n",
            "Best valid f1 = 0.4502172720871353\n",
            "Best valid rec = 0.41335740072202165\n",
            "Classification report = \n",
            " {\n",
            "    \"-1.0\": {\n",
            "        \"f1-score\": 0.0,\n",
            "        \"precision\": 0.0,\n",
            "        \"recall\": 0.0,\n",
            "        \"support\": 0\n",
            "    },\n",
            "    \"0.0\": {\n",
            "        \"f1-score\": 0.6847697756788667,\n",
            "        \"precision\": 0.7671957671957672,\n",
            "        \"recall\": 0.6183368869936035,\n",
            "        \"support\": 469\n",
            "    },\n",
            "    \"1.0\": {\n",
            "        \"f1-score\": 0.07368421052631578,\n",
            "        \"precision\": 0.04666666666666667,\n",
            "        \"recall\": 0.175,\n",
            "        \"support\": 40\n",
            "    },\n",
            "    \"2.0\": {\n",
            "        \"f1-score\": 0.3395061728395061,\n",
            "        \"precision\": 0.3160919540229885,\n",
            "        \"recall\": 0.36666666666666664,\n",
            "        \"support\": 150\n",
            "    },\n",
            "    \"3.0\": {\n",
            "        \"f1-score\": 0.30340557275541796,\n",
            "        \"precision\": 0.30625,\n",
            "        \"recall\": 0.3006134969325153,\n",
            "        \"support\": 163\n",
            "    },\n",
            "    \"4.0\": {\n",
            "        \"f1-score\": 0.07142857142857142,\n",
            "        \"precision\": 0.0423728813559322,\n",
            "        \"recall\": 0.22727272727272727,\n",
            "        \"support\": 22\n",
            "    },\n",
            "    \"5.0\": {\n",
            "        \"f1-score\": 0.14857142857142855,\n",
            "        \"precision\": 0.203125,\n",
            "        \"recall\": 0.11711711711711711,\n",
            "        \"support\": 111\n",
            "    },\n",
            "    \"6.0\": {\n",
            "        \"f1-score\": 0.3679245283018868,\n",
            "        \"precision\": 0.6610169491525424,\n",
            "        \"recall\": 0.2549019607843137,\n",
            "        \"support\": 153\n",
            "    },\n",
            "    \"7.0\": {\n",
            "        \"f1-score\": 0.0,\n",
            "        \"precision\": 0.0,\n",
            "        \"recall\": 0.0,\n",
            "        \"support\": 0\n",
            "    },\n",
            "    \"accuracy\": 0.41335740072202165,\n",
            "    \"macro avg\": {\n",
            "        \"f1-score\": 0.2210322511224437,\n",
            "        \"precision\": 0.2603021353770997,\n",
            "        \"recall\": 0.22887876175188263,\n",
            "        \"support\": 1108\n",
            "    },\n",
            "    \"weighted avg\": {\n",
            "        \"f1-score\": 0.4502172720871353,\n",
            "        \"precision\": 0.5267407005370932,\n",
            "        \"recall\": 0.41335740072202165,\n",
            "        \"support\": 1108\n",
            "    }\n",
            "}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = plt.subplot()\n",
        "sns.heatmap(result_matrix, annot=True, fmt='g', ax=ax);\n",
        "labels = ['neu', 'fear', 'surp', 'joy', 'disg', 'sad', 'ang']\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "R52G-1HpGCDX",
        "outputId": "8d4c0026-01d9-4305-cecd-7097754ed3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}