# 3-Modal-Cross-Bert

Model for multimodal multiclass sentiment or emotion recognition.
Based on the Cross-Bert model: https://github.com/thuiar/Cross-Modal-BERT with video features additions.

Used datasets:
* Meld (https://paperswithcode.com/dataset/meld)
* MOSI (https://paperswithcode.com/dataset/multimodal-opinionlevel-sentiment-intensity)
* MOSEI (https://paperswithcode.com/dataset/cmu-mosei)
* IEMOCAP (https://paperswithcode.com/dataset/iemocap)

# Intermodal interaction

Model for multimodal multiclass sentiment or emotion recognition.

Used datasets:
* Meld (https://paperswithcode.com/dataset/meld)
* MOSI (https://paperswithcode.com/dataset/multimodal-opinionlevel-sentiment-intensity)
* MOSEI (https://paperswithcode.com/dataset/cmu-mosei)
* IEMOCAP (https://paperswithcode.com/dataset/iemocap)
* RESD (https://huggingface.co/datasets/Aniemore/resd_annotated)
* Dusha (https://paperswithcode.com/dataset/dusha)
